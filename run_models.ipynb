{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2522581-45b7-49f3-9312-0259fd150dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chris\\anaconda3\\envs\\relu_ranger\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install -q bitsandbytes accelerate loralib datasets\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a51512-b462-44a4-ba11-1882b568c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import datasets as ds\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import OPTForCausalLM, AutoTokenizer, AutoConfig\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from random import randint, sample\n",
    "\n",
    "from data_utils import (\n",
    "    load_glue_datasets,\n",
    "    load_hans_dataset,\n",
    "    load_paws_qqp_dataset,\n",
    "    get_dataset,\n",
    ")\n",
    "from context_utils import (\n",
    "    create_few_shot_context, \n",
    "    select_demonstrations, \n",
    "    create_train_batch_token,\n",
    "    create_validation_batch_token,\n",
    "    create_paws_qqp_batch_token,\n",
    "    create_hans_train_batch_token\n",
    ")\n",
    "from training_utils import (\n",
    "    set_seed,\n",
    "    CastOutputToFloat,\n",
    "    get_model,\n",
    "    plot_losses,\n",
    "    train,\n",
    "    predict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead6567c-cd31-4ad3-9562-7f5cbdb07d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.logging.set_verbosity(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a75959-3c9a-451f-a3e7-ad4fcadc7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_seed(seed):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     ds.logging.set_verbosity(40)\n",
    "\n",
    "# def print_trainable_parameters(model):\n",
    "#     trainable_params = 0\n",
    "#     all_param = 0\n",
    "#     for _, param in model.named_parameters():\n",
    "#         all_param += param.numel()\n",
    "#         if param.requires_grad:\n",
    "#             trainable_params += param.numel()\n",
    "#     print(\n",
    "#         f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "#     )\n",
    "\n",
    "# class CastOutputToFloat(torch.nn.Sequential):\n",
    "#   def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "\n",
    "# def get_model(model_name):\n",
    "#     model_name = \"facebook/\" + model_name\n",
    "#     config = AutoConfig.from_pretrained(model_name)\n",
    "#     config.hidden_dropout_prob = 0.1\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_name) # tokenizer\n",
    "#     teacher_model = OPTForCausalLM.from_pretrained(model_name) # teacher model\n",
    "#     student_model = OPTForCausalLM.from_pretrained(model_name, config=config) # student model\n",
    "\n",
    "#     for param in student_model.parameters():\n",
    "#         param.requires_grad = False\n",
    "#         if param.ndim == 1:\n",
    "#             param.data = param.data.to(torch.float32)\n",
    "    \n",
    "#     student_model.gradient_checkpointing_enable()\n",
    "#     student_model.enable_input_require_grads()\n",
    "#     student_model.lm_head = CastOutputToFloat(student_model.lm_head)\n",
    "\n",
    "#     config = LoraConfig(\n",
    "#         r=16,\n",
    "#         lora_alpha=32,\n",
    "#         lora_dropout=0.05,\n",
    "#         bias=\"none\",\n",
    "#         task_type=\"CAUSAL_LM\"\n",
    "#     )\n",
    "    \n",
    "#     student_model = get_peft_model(student_model, config)\n",
    "#     return tokenizer, student_model, teacher_model\n",
    "\n",
    "# def get_dataset(data_set_used):\n",
    "#     datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "    \n",
    "#     if data_set_used in ['mnli', 'rte', 'hans']:\n",
    "#         teacher_prompt = 'Think logically. Are the following sentences examples of entailment, yes or no?'\n",
    "#         student_prompt = 'Are the following sentences examples of entailment, yes or no?'\n",
    "#     elif data_set_used in ['qqp', 'paws-qqp']:\n",
    "#         teacher_prompt = 'Think logically. Are the following sentences duplicates or paraphrases of each other, yes or no?'\n",
    "#         student_prompt = 'Are the following sentences duplicates or paraphrases of each other, yes or no?'\n",
    "\n",
    "#     return datasets, labels, num_labels, teacher_prompt, student_prompt\n",
    "    \n",
    "# # Assuming `losses` is the list of epoch losses returned from the `train` function\n",
    "# def plot_losses(losses):\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.plot(losses, marker='o', linestyle='-', color='b')\n",
    "#     plt.title('Training Loss Per Epoch')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Average Loss')\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "# def train(teacher_model, student_model, data, epochs=10, batch_size=32, device='cpu'):\n",
    "#     student_model.to(device)\n",
    "#     teacher_model.to(device)\n",
    "#     print(id(student_model))\n",
    "#     print(id(teacher_model))\n",
    "    \n",
    "#     student_model.train()\n",
    "#     optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-5, weight_decay=0.000001 )\n",
    "#     epoch_losses = []\n",
    "\n",
    "#     if (len(data) % batch_size != 0):\n",
    "#         num_batches = (len(data) // batch_size) + 1\n",
    "#     else:\n",
    "#         num_batches  = len(data) // batch_size\n",
    "\n",
    "#     num_datapoints = len(data)\n",
    "#     total_steps = num_batches * epochs\n",
    "#     warmup_ratio = int(0.1 * total_steps) \n",
    "    \n",
    "#     def lr_schedular(current_step: int):\n",
    "#         if current_step < warmup_ratio:\n",
    "#             return float(current_step) / float(max(1,warmup_ratio))\n",
    "#         return 1.\n",
    "    \n",
    "#     scheduler = LambdaLR(optimizer, lr_schedular)\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         total_loss = 0\n",
    "#         samples_left = num_datapoints\n",
    "        \n",
    "#         for i in range(num_batches):\n",
    "#             batch_loss = 0\n",
    "#             if ((samples_left - batch_size) >= 0):\n",
    "#                 samples_used = batch_size\n",
    "#                 samples_left -= batch_size\n",
    "#             else:\n",
    "#                 samples_used = samples_left\n",
    "#                 samples_left = 0\n",
    "#             for j in range(samples_used):\n",
    "#                 index = i * batch_size + j\n",
    "                \n",
    "#                 teacher_inputs = data[index]['context'].to(device)\n",
    "#                 student_inputs = data[index]['query'].to(device)\n",
    "                                \n",
    "#                 teacher_outputs = teacher_model.generate(\n",
    "#                     **teacher_inputs,\n",
    "#                     max_length=teacher_inputs['input_ids'].shape[-1] + 1,\n",
    "#                     output_scores=True,\n",
    "#                     return_dict_in_generate=True\n",
    "#                 )\n",
    "#                 teacher_probs = torch.nn.functional.softmax(teacher_outputs.scores[0], dim=-1)\n",
    "                \n",
    "#                 student_logits = student_model(**student_inputs).logits\n",
    "#                 student_probs = torch.nn.functional.softmax(student_logits[:, -1, :], dim=-1)\n",
    "                \n",
    "#                 kl_divergence = torch.nn.functional.kl_div(student_probs.log(), teacher_probs, reduction='batchmean')\n",
    "                \n",
    "#                 optimizer.zero_grad()\n",
    "#                 kl_divergence.backward()\n",
    "#                 optimizer.step()\n",
    "\n",
    "#                 batch_loss += kl_divergence.item()\n",
    "\n",
    "#             # Average loss for the batch\n",
    "#             batch_loss /= batch_size\n",
    "#             total_loss += batch_loss\n",
    "#             scheduler.step()\n",
    "#             #print(f\"Epoch {epoch + 1}, Batch {i + 1}, Average Loss: {batch_loss}\")\n",
    "\n",
    "\n",
    "#         # Average loss for the epoch\n",
    "#         epoch_loss = total_loss / num_batches\n",
    "#         epoch_losses.append(epoch_loss)\n",
    "\n",
    "#         print(f\"Epoch {epoch + 1}, Total Loss: {epoch_loss}\")\n",
    "        \n",
    "#     print(f\"Total loss : {total_loss/epochs}\")\n",
    "#     plot_losses(epoch_losses)\n",
    "#     # torch.save(student_model, './models/student.pth')\n",
    "\n",
    "# def predict(model, source, target=None, device='cpu'):\n",
    "#     predict = []\n",
    "#     for token in source:\n",
    "#         output = model.generate(**token, max_length=token['input_ids'].shape[-1] + 1).to(device)\n",
    "#         decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "#         predicted_label = decoded_output.split(\"Label:\")[-1].strip().split('.')[0].strip()\n",
    "#         predict.append(predicted_label)\n",
    "        \n",
    "#     return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a750150-12ce-4d60-8cb9-3ef580899e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_job(dataset_used, indomain, model_name, epochs, val_len, train_len, context_len, seed):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    datasets, labels, num_labels, teacher_prompt, student_prompt = get_dataset(dataset_used)\n",
    "    \n",
    "    set_seed(seed)\n",
    "    print('starting run: {}'.format(seed))\n",
    "    print('loading model')\n",
    "    tokenizer, student_model, teacher_model = get_model(model_name)\n",
    "    print(\"finished loading model\")\n",
    "\n",
    "    print(\"loading data\")\n",
    "    if (dataset_used in ['mnli','rte'] and indomain == False):\n",
    "        print(\"running a hans-based load\")\n",
    "        if dataset_used == 'mnli':\n",
    "            datasets2, labels2, num_labels2, teacher_prompt2, student_prompt2 = get_dataset('rte')\n",
    "            mnli_dataset = datasets \n",
    "            rte_dataset = datasets2\n",
    "        else:\n",
    "            datasets2, labels2, num_labels2, teacher_prompt2, student_prompt2 = get_dataset('mnli')\n",
    "            mnli_dataset = datasets2 \n",
    "            rte_dataset = datasets\n",
    "\n",
    "        train_data_tokens, train_data_strings, indices, context_indices = create_hans_train_batch_token(\n",
    "            mnli_dataset,\n",
    "            rte_dataset,\n",
    "            teacher_description = teacher_prompt, \n",
    "            student_description = student_prompt, \n",
    "            tokenizer=tokenizer, \n",
    "            seed=seed, \n",
    "            device=device,\n",
    "            num_shots = context_len,\n",
    "            num_train_samps=train_len,\n",
    "        )\n",
    "    else:\n",
    "        train_data_tokens, train_data_strings, indices, context_indices = create_train_batch_token(\n",
    "            dataset_used, \n",
    "            datasets, \n",
    "            teacher_description = teacher_prompt, \n",
    "            student_description = student_prompt, \n",
    "            tokenizer=tokenizer, \n",
    "            seed=seed, \n",
    "            device=device,\n",
    "            num_shots = context_len,\n",
    "            num_train_samps=train_len,\n",
    "        )\n",
    "\n",
    "    print(\"finished loading data\")\n",
    "\n",
    "    print(\"training model\")\n",
    "    train(teacher_model, student_model, train_data_tokens, epochs = epochs, device=device)\n",
    "    print(\"finished training model\")\n",
    "\n",
    "    if indomain: \n",
    "        print(\"predicting on validation set\")\n",
    "       \n",
    "        student_prompt_tokens, student_prompt_strings, val_indices, val_labels = create_validation_batch_token(\n",
    "            dataset_used, datasets, prompt_descr=student_prompt ,tokenizer=tokenizer, device=device, limit=val_len\n",
    "        )\n",
    "        prediction = predict(student_model, student_prompt_tokens, tokenizer = tokenizer, device=device)  \n",
    "        print(\"finished predicting on validation set\")\n",
    "    \n",
    "        accuracy = accuracy_score(prediction,val_labels)\n",
    "        print(\"finished run {}\".format(seed))\n",
    "        print(\"final result\",accuracy)\n",
    "        meta_domain_name=\"in\"\n",
    "        validation_set=\"indomain\"\n",
    "    else:\n",
    "        if dataset_used == 'qqp':\n",
    "            print(\"predicting on paws_qqp\")\n",
    "            validation_set = 'paws_qqp'\n",
    "            \n",
    "            dataset, label_list, num_labels = load_paws_qqp_dataset('dev_and_test.tsv')\n",
    "\n",
    "            student_prompt_tokens, student_prompt_strings, val_indices, val_labels = create_paws_qqp_batch_token(\n",
    "                dataset, prompt_descr=student_prompt ,tokenizer=tokenizer, device=device, limit=val_len\n",
    "            )\n",
    "            prediction = predict(student_model, student_prompt_tokens, tokenizer = tokenizer, device=device)  \n",
    "            print(\"finished predicting on validation set\")\n",
    "        \n",
    "            accuracy = accuracy_score(prediction,val_labels)\n",
    "            print(\"finished run {}\".format(seed))\n",
    "            print(\"final result\",accuracy)           \n",
    "        else:\n",
    "            print(\"predicting on hans\")\n",
    "            dataset, label_list, num_labels = load_hans_dataset()\n",
    "            validation_set = 'hans'\n",
    "\n",
    "            student_prompt_tokens, student_prompt_strings, val_indices, val_labels = create_hans_batch_token(\n",
    "                dataset, prompt_descr=student_prompt ,tokenizer=tokenizer, device=device, limit=val_len\n",
    "            )\n",
    "            prediction = predict(student_model, student_prompt_tokens, tokenizer = tokenizer, device=device)  \n",
    "            print(\"finished predicting on validation set\")\n",
    "        \n",
    "            accuracy = accuracy_score(prediction,val_labels)\n",
    "            print(\"finished run {}\".format(seed))\n",
    "            print(\"final result\",accuracy)  \n",
    "        meta_domain_name=\"out\"\n",
    "\n",
    "    if not os.path.exists('output'):\n",
    "        os.makedirs('output')\n",
    "    \n",
    "    meta_data_file_name = f'{dataset_used}_{model_name}_{seed}_{meta_domain_name}_{epochs}_{val_len}_{train_len}_{context_len}.json'\n",
    "    metadata_loc = os.path.join('output',meta_data_file_name)\n",
    "    metadata = {\n",
    "        'accuracy': accuracy,\n",
    "        'query_indices': indices,\n",
    "        'context_indices': context_indices.tolist(),\n",
    "        'validation_indices': val_indices.tolist(),\n",
    "        'model_name': model_name,\n",
    "        'dataset_used': dataset_used,\n",
    "        'validation_used': validation_set,\n",
    "        'indomain':meta_domain_name,\n",
    "        'seed': seed,\n",
    "        'epochs': epochs,\n",
    "        'val_len': val_len,\n",
    "        'train_len': train_len,\n",
    "        'context_len': context_len\n",
    "    }\n",
    "    \n",
    "    with open(metadata_loc, 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd48760-4f90-44ad-a4dc-f0d738a3dadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTED\n",
      "starting run: 0\n",
      "loading model\n",
      "finished loading model\n",
      "loading data\n",
      "running a hans-based load\n",
      "hans only works on even training numbers...testing\n",
      "finished loading data\n",
      "training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    }
   ],
   "source": [
    "runs = 1\n",
    "dataset_used = 'mnli'\n",
    "indomain=False\n",
    "model_name = \"opt-125m\"\n",
    "epochs = 20\n",
    "val_len = 100\n",
    "train_len = 32\n",
    "context_len = 16\n",
    "\n",
    "print(\"STARTED\")\n",
    "for seed in range(runs):\n",
    "    run_job(dataset_used,indomain,model_name,epochs,val_len, train_len, context_len,seed)\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd484729-1634-48b2-abcc-d0d3ee429eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
