{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import OPTForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
    "model = OPTForCausalLM.from_pretrained(\"facebook/opt-125m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Premise: i don't know um do you do a lot of camping,\n",
    "            hypothesis: I know exactly,\n",
    "            label: Contradiction\n",
    "\n",
    "            Premise: This site includes a list of all award winners and a searchable database of Government Executive articles, \n",
    "            Hypothesis: The Government Executive articles housed on the website are not able to be searched, \n",
    "            Label: Contradiction\n",
    "\n",
    "            Premise: The new rights are nice enough, \n",
    "            Hypothesis: Everyone really likes the newest benefits, \n",
    "            Label: Entailment\n",
    "                        \n",
    "            Premise: uh i don't know i i have mixed emotions about him uh sometimes i like him but at the same times i love to see somebody beat him\n",
    "            hypothesis: I like him for the most part, but would still enjoy seeing someone beat him very hard and enjoy that sight.\n",
    "            Label:\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contradiction'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ids = model.generate(inputs.input_ids, max_length=inputs['input_ids'].shape[-1] + 10)\n",
    "output_text_ = tokenizer.decode(generate_ids[0], skip_special_tokens=True)\n",
    "label_out = output_text_.split(\"Label:\")[-1].strip().split('.')[0].strip()\n",
    "label_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    With MNLI tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1399bd24a64239a5c5db1243353c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 52.2M/52.2M [00:01<00:00, 50.4MB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 1.21M/1.21M [00:00<00:00, 14.6MB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 1.25M/1.25M [00:00<00:00, 5.73MB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 1.22M/1.22M [00:00<00:00, 21.1MB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 1.26M/1.26M [00:00<00:00, 19.8MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bdf5c12d604617a59cafd867a14085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61205b418e844c28360bed800ae0684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14e5c983b8344acba058225bbc8b8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d6b65d83984164b6e7e3f804fbffbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_matched split:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c5a256028a4de8a1fbd3ce67af9a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_mismatched split:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "    num_rows: 9815\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"nyu-mll/glue\", \"mnli\", split='validation_matched')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_text(label):\n",
    "    return [\"entailment\", \"neutral\", \"contradiction\"][label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_prompt(context_examples, query_example):\n",
    "    context_prompt = \"\"\n",
    "    for example in context_examples:\n",
    "        premise = example['premise']\n",
    "        hypothesis = example['hypothesis']\n",
    "        label = label_to_text(example['label'])\n",
    "        context_prompt += f\"Premise: {premise}, Hypothesis: {hypothesis}, Label: {label}\"\n",
    "\n",
    "    query_premise = query_example['premise']\n",
    "    query_hypothesis = query_example['hypothesis']\n",
    "    print('true lbl: ', label_to_text(query_example['label']))\n",
    "    query_prompt = f\"Premise: {query_premise}, Hypothesis: {query_hypothesis}, Label:\"\n",
    "    \n",
    "    return context_prompt + query_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'premise': 'The new rights are nice enough', 'hypothesis': 'Everyone really likes the newest benefits ', 'label': 1, 'idx': 0}, {'premise': 'This site includes a list of all award winners and a searchable database of Government Executive articles.', 'hypothesis': 'The Government Executive articles housed on the website are not able to be searched.', 'label': 2, 'idx': 1}]\n",
      "{'premise': \"uh i don't know i i have mixed emotions about him uh sometimes i like him but at the same times i love to see somebody beat him\", 'hypothesis': 'I like him for the most part, but would still enjoy seeing someone beat him.', 'label': 0, 'idx': 2}\n",
      "true lbl:  entailment\n",
      "Predicted Label: I\n"
     ]
    }
   ],
   "source": [
    "def classify_with_context(context_data, query_data, tokenizer, model):\n",
    "    prompt = create_extended_prompt(context_data, query_data)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generate_ids = model.generate(inputs['input_ids'], max_length=inputs['input_ids'].shape[-1] + 1)\n",
    "    output_text = tokenizer.decode(generate_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    predicted_label = output_text.split(\"Label:\")[-1].strip().split('.')[0].strip()\n",
    "    return predicted_label\n",
    "\n",
    "context_examples = [{key: value[i] for key, value in dataset[:2].items()} for i in range(2)]\n",
    "query_example = {key: value for key, value in dataset[2].items()}\n",
    "\n",
    "print(context_examples)\n",
    "print(query_example)\n",
    "\n",
    "predicted_label = classify_with_context(context_examples, query_example, tokenizer, model)\n",
    "print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
