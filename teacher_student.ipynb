{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manishrajosti/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import OPTForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "teacher_model = OPTForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "student_model = OPTForCausalLM.from_pretrained(\"facebook/opt-350m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nyu-mll/glue\", \"mnli\", split='validation_matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_text(label):\n",
    "    return [\"entailment\", \"neutral\", \"contradiction\"][label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_examples = [{key: value[i] for key, value in dataset[1:3].items()} for i in range(2)]\n",
    "query_example = {key: value for key, value in dataset[3].items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'premise': 'This site includes a list of all award winners and a searchable database of Government Executive articles.',\n",
       "  'hypothesis': 'The Government Executive articles housed on the website are not able to be searched.',\n",
       "  'label': 2,\n",
       "  'idx': 1},\n",
       " {'premise': \"uh i don't know i i have mixed emotions about him uh sometimes i like him but at the same times i love to see somebody beat him\",\n",
       "  'hypothesis': 'I like him for the most part, but would still enjoy seeing someone beat him.',\n",
       "  'label': 0,\n",
       "  'idx': 2}]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': \"yeah i i think my favorite restaurant is always been the one closest  you know the closest as long as it's it meets the minimum criteria you know of good food\",\n",
       " 'hypothesis': 'My favorite restaurants are always at least a hundred miles away from my house. ',\n",
       " 'label': 2,\n",
       " 'idx': 3}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_create_prompt(premise, hypothesis, label=None):\n",
    "    prompt = f\"Answer if it is entailment or Contradiction. Premise: {premise}, Hypothesis: {hypothesis}, Label:entailment or Contradiction\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_create_prompt(premise, hypothesis, label=None):\n",
    "    prompt = f\"Premise: {premise}, Hypothesis: {hypothesis}\"\n",
    "    if label is not None:\n",
    "        prompt += f\", Label: {label_to_text(label)}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_prompt(context_examples, query_example):\n",
    "    context_prompt = \"\"\n",
    "    for example in context_examples:\n",
    "        premise = example['premise']\n",
    "        hypothesis = example['hypothesis']\n",
    "        label = example['label']\n",
    "        context_prompt += t_create_prompt(premise, hypothesis, label) + \". \"\n",
    "    \n",
    "    query_premise = query_example['premise']\n",
    "    query_hypothesis = query_example['hypothesis']\n",
    "    query_prompt = t_create_prompt(query_premise, query_hypothesis) \n",
    "    return context_prompt + query_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Premise: This site includes a list of all award winners and a searchable database of Government Executive articles., Hypothesis: The Government Executive articles housed on the website are not able to be searched., Label: contradiction. Premise: uh i don't know i i have mixed emotions about him uh sometimes i like him but at the same times i love to see somebody beat him, Hypothesis: I like him for the most part, but would still enjoy seeing someone beat him., Label: entailment. Premise: yeah i i think my favorite restaurant is always been the one closest  you know the closest as long as it's it meets the minimum criteria you know of good food, Hypothesis: My favorite restaurants are always at least a hundred miles away from my house. \""
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_prompt = create_extended_prompt(context_examples, query_example)\n",
    "student_prompt = s_create_prompt(query_example['premise'], query_example['hypothesis'])\n",
    "\n",
    "teacher_inputs = tokenizer(teacher_prompt, return_tensors=\"pt\")\n",
    "student_inputs = tokenizer(student_prompt, return_tensors=\"pt\")\n",
    "\n",
    "teacher_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_outputs = teacher_model.generate(**teacher_inputs, max_length=teacher_inputs['input_ids'].shape[-1] + 2)\n",
    "# t_output_text = tokenizer.decode(teacher_outputs[0], skip_special_tokens=True)\n",
    "# teacher_predicted_label = t_output_text.split(\"Label:\")[-1].strip().split('.')[0].strip()\n",
    "# teacher_predicted_label\n",
    "\n",
    "teacher_outputs = student_model(**student_inputs, labels=student_inputs['input_ids'])\n",
    "t_logits = teacher_outputs.logits\n",
    "t_probs = torch.nn.functional.softmax(t_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_outputs = student_model(**student_inputs, labels=student_inputs['input_ids'])\n",
    "student_logits = student_outputs.logits\n",
    "student_probs = torch.nn.functional.softmax(student_logits, dim=-1)\n",
    "\n",
    "# student_outputs = student_model.generate(**student_inputs, max_length=student_inputs['input_ids'].shape[-1] + 10)\n",
    "# s_output_text = tokenizer.decode(student_outputs[0], skip_special_tokens=True)\n",
    "# student_predicted_label = s_output_text.split(\"Label:\")[-1].strip().split('.')[0].strip()\n",
    "# print(student_predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
       "      (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2119, 0.5761, 0.2119]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3642)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_index = {'entailment': 0, 'entailment or Contradiction': 1, 'contradiction': 2}\n",
    "# teacher_label_idx = torch.tensor([label_index[teacher_predicted_label]], dtype=torch.long)\n",
    "# student_label_idx = torch.tensor([label_index[student_predicted_label]], dtype=torch.long)\n",
    "\n",
    "# teacher_probs = torch.nn.functional.one_hot(teacher_label_idx, num_classes=3).float()\n",
    "# student_probs = torch.nn.functional.one_hot(student_label_idx, num_classes=3).float()\n",
    "# student_probs = torch.nn.functional.softmax(student_probs, dim=-1)\n",
    "# teacher_probs = torch.nn.functional.softmax(teacher_probs, dim=-1)\n",
    "\n",
    "# print(student_probs)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(student_model.parameters(), lr=0.001)\n",
    "\n",
    "# total_loss = 0\n",
    "# criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "# loss = criterion(student_probs.log(), teacher_probs)\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9139, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "loss = criterion(student_probs.log(), t_probs)\n",
    "loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, Average Loss: 2.728483200073242\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "student_model.zero_grad()\n",
    "loss.backward()\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=0.001)\n",
    "optimizer.step()\n",
    "total_loss += loss.item()\n",
    "\n",
    "print(f\"1, Average Loss: {total_loss/len(query_example)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metaLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
