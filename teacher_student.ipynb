{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import OPTForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "teacher_model = OPTForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "student_model = OPTForCausalLM.from_pretrained(\"facebook/opt-350m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nyu-mll/glue\", \"mnli\", split='validation_matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_text(label):\n",
    "    return [\"entailment\", \"neutral\", \"contradiction\"][label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_examples = [{key: value[i] for key, value in dataset[5:7].items()} for i in range(2)]\n",
    "query_example = {key: value for key, value in dataset[7].items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'premise': \"well that would be a help i wish they would do that here we have got so little landfill space left that we're going to run out before the end of this decade and it's really going to be\",\n",
       "  'hypothesis': 'We have plenty of space in the landfill.',\n",
       "  'label': 2,\n",
       "  'idx': 5},\n",
       " {'premise': 'yeah i know and i did that all through college and it worked too',\n",
       "  'hypothesis': 'I did that all through college but it never worked ',\n",
       "  'label': 2,\n",
       "  'idx': 6}]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': \"Calcutta seems to be the only other production center having any pretensions to artistic creativity at all, but ironically you're actually more likely to see the works of Satyajit Ray or Mrinal Sen shown in Europe or North America than in India itself.\",\n",
       " 'hypothesis': \"Most of Mrinal Sen's work can be found in European collections.\",\n",
       " 'label': 1,\n",
       " 'idx': 7}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_create_prompt(premise, hypothesis, label=None):\n",
    "    prompt = f\"Label if this is entailment or contradiction.\\nPremise: {premise},\\nHypothesis: {hypothesis},\\nLabel:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_create_prompt(premise, hypothesis, label=None):\n",
    "    prompt = f\"\\nPremise: {premise}, \\nHypothesis: {hypothesis}\"\n",
    "    if label is not None:\n",
    "        prompt += f\",\\nLabel: {label_to_text(label)}\"\n",
    "    if label is None:\n",
    "        prompt += f\",\\nLabel:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_prompt(context_examples, query_example):\n",
    "    context_prompt = \"\"\n",
    "    for example in context_examples:\n",
    "        premise = example['premise']\n",
    "        hypothesis = example['hypothesis']\n",
    "        label = example['label']\n",
    "        context_prompt += t_create_prompt(premise, hypothesis, label) + \"\\n\"\n",
    "    \n",
    "    query_premise = query_example['premise']\n",
    "    query_hypothesis = query_example['hypothesis']\n",
    "    query_prompt = t_create_prompt(query_premise, query_hypothesis) \n",
    "    return context_prompt + query_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Premise: well that would be a help i wish they would do that here we have got so little landfill space left that we're going to run out before the end of this decade and it's really going to be, \n",
      "Hypothesis: We have plenty of space in the landfill.,\n",
      "Label: contradiction\n",
      "\n",
      "Premise: yeah i know and i did that all through college and it worked too, \n",
      "Hypothesis: I did that all through college but it never worked ,\n",
      "Label: contradiction\n",
      "\n",
      "Premise: Calcutta seems to be the only other production center having any pretensions to artistic creativity at all, but ironically you're actually more likely to see the works of Satyajit Ray or Mrinal Sen shown in Europe or North America than in India itself., \n",
      "Hypothesis: Most of Mrinal Sen's work can be found in European collections.,\n",
      "Label:\n"
     ]
    }
   ],
   "source": [
    "teacher_prompt = create_extended_prompt(context_examples, query_example)\n",
    "student_prompt = s_create_prompt(query_example['premise'], query_example['hypothesis'])\n",
    "\n",
    "teacher_inputs = tokenizer(teacher_prompt, return_tensors=\"pt\")\n",
    "student_inputs = tokenizer(student_prompt, return_tensors=\"pt\")\n",
    "\n",
    "print(teacher_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Premise: well that would be a help i wish they would do that here we have got so little landfill space left that we're going to run out before the end of this decade and it's really going to be, \n",
      "Hypothesis: We have plenty of space in the landfill.,\n",
      "Label: contradiction\n",
      "\n",
      "Premise: yeah i know and i did that all through college and it worked too, \n",
      "Hypothesis: I did that all through college but it never worked,\n",
      "Label: contradiction\n",
      "\n",
      "Premise: Calcutta seems to be the only other production center having any pretensions to artistic creativity at all, but ironically you're actually more likely to see the works of Satyajit Ray or Mrinal Sen shown in Europe or North America than in India itself., \n",
      "Hypothesis: Most of Mrinal Sen's work can be found in European collections.,\n",
      "Label: contradiction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teacher_outputs = teacher_model.generate(**teacher_inputs, max_length=teacher_inputs['input_ids'].shape[-1] + 2)\n",
    "t_output_text = tokenizer.decode(teacher_outputs[0], skip_special_tokens=True)\n",
    "print(t_output_text)\n",
    "teacher_predicted_label = t_output_text.split(\"Label:\")[-1].strip().split('.')[0].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " contradiction\n",
      "torch.Size([1, 189]) torch.Size([1, 50272])\n",
      "torch.Size([1, 50272])\n"
     ]
    }
   ],
   "source": [
    "teacher_outputs_1 = teacher_model.generate(**teacher_inputs, max_length=teacher_inputs['input_ids'].shape[-1] + 1, output_scores=True, return_dict_in_generate=True)\n",
    "teacher_probs_1 = torch.nn.functional.softmax(teacher_outputs_1.scores[0], dim=-1)\n",
    "print(tokenizer.decode(teacher_outputs_1[0][0][-1], skip_special_tokens=True))\n",
    "print(teacher_outputs_1[0].shape, teacher_outputs_1.scores[0].shape)\n",
    "\n",
    "argmax_index = torch.argmax(teacher_outputs_1.scores[0])\n",
    "print(teacher_probs_1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
       "      (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50272])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# student_outputs = student_model.generate(**student_inputs, max_length=student_inputs['input_ids'].shape[-1] + 2)\n",
    "# s_output_text = tokenizer.decode(student_outputs[0], skip_special_tokens=True)\n",
    "# student_predicted_label = s_output_text.split(\"Label:\")[-1].strip().split('.')[0].strip()\n",
    "# print(s_output_text)\n",
    "\n",
    "# student_outputs = student_model.generate(**student_inputs, max_length=student_inputs['input_ids'].shape[-1] + 1, output_scores=True, return_dict_in_generate=True)\n",
    "# student_probs_1 = torch.nn.functional.softmax(student_outputs.scores[0], dim=-1)\n",
    "\n",
    "# print(tokenizer.decode(student_outputs[0][0][-1], skip_special_tokens=True))\n",
    "# print(student_outputs[0].shape, student_outputs.scores[0].shape)\n",
    "\n",
    "# s_argmax_index = torch.argmax(student_outputs.scores[0])\n",
    "# print(student_probs_1.shape, s_argmax_index)\n",
    "# student_probs_1.requires_grad\n",
    "\n",
    "student_logits = student_model(**student_inputs).logits \n",
    "student_probs_1 = torch.nn.functional.softmax(student_logits[:,-1,:], dim=-1)\n",
    "student_probs_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.3630, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=0.001)\n",
    "\n",
    "kl_divergence = torch.nn.functional.kl_div(student_probs_1.log(), teacher_probs_1, reduction='batchmean')\n",
    "\n",
    "print(kl_divergence)\n",
    "kl_divergence.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, Average Loss: 2.8407492637634277\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "\n",
    "optimizer.zero_grad()\n",
    "kl_divergence.backward()\n",
    "optimizer.step()\n",
    "\n",
    "total_loss += kl_divergence.item()\n",
    "\n",
    "print(f\"1, Average Loss: {total_loss/len(query_example)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metaLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
