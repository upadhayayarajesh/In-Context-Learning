{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2522581-45b7-49f3-9312-0259fd150dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q bitsandbytes accelerate loralib datasets\n",
    "# !pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a51512-b462-44a4-ba11-1882b568c29f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_dataset' from 'data_utils' (C:\\Users\\Chris\\Desktop\\classes\\deep_learning\\final_project\\main\\data_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoraConfig, get_peft_model\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m randint, sample\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     load_glue_datasets,\n\u001b[0;32m     20\u001b[0m     load_hans_dataset,\n\u001b[0;32m     21\u001b[0m     load_paws_qqp_dataset,\n\u001b[0;32m     22\u001b[0m     get_dataset,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontext_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     create_few_shot_context, \n\u001b[0;32m     26\u001b[0m     select_demonstrations, \n\u001b[0;32m     27\u001b[0m     create_train_batch_token,\n\u001b[0;32m     28\u001b[0m     create_validation_batch_token,\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtraining_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     31\u001b[0m     set_seed,\n\u001b[0;32m     32\u001b[0m     CastOutputToFloat,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     predict\n\u001b[0;32m     37\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_dataset' from 'data_utils' (C:\\Users\\Chris\\Desktop\\classes\\deep_learning\\final_project\\main\\data_utils.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import datasets as ds\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import OPTForCausalLM, AutoTokenizer, AutoConfig\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from random import randint, sample\n",
    "\n",
    "from data_utils import (\n",
    "    load_glue_datasets,\n",
    "    load_hans_dataset,\n",
    "    load_paws_qqp_dataset,\n",
    "    get_dataset,\n",
    ")\n",
    "from context_utils import (\n",
    "    create_few_shot_context, \n",
    "    select_demonstrations, \n",
    "    create_train_batch_token,\n",
    "    create_validation_batch_token,\n",
    ")\n",
    "from training_utils import (\n",
    "    set_seed,\n",
    "    CastOutputToFloat,\n",
    "    get_model,\n",
    "    plot_losses,\n",
    "    train,\n",
    "    predict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6567c-cd31-4ad3-9562-7f5cbdb07d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.logging.set_verbosity(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a75959-3c9a-451f-a3e7-ad4fcadc7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_seed(seed):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     ds.logging.set_verbosity(40)\n",
    "\n",
    "# def print_trainable_parameters(model):\n",
    "#     trainable_params = 0\n",
    "#     all_param = 0\n",
    "#     for _, param in model.named_parameters():\n",
    "#         all_param += param.numel()\n",
    "#         if param.requires_grad:\n",
    "#             trainable_params += param.numel()\n",
    "#     print(\n",
    "#         f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "#     )\n",
    "\n",
    "# class CastOutputToFloat(torch.nn.Sequential):\n",
    "#   def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "\n",
    "# def get_model(model_name):\n",
    "#     model_name = \"facebook/\" + model_name\n",
    "#     config = AutoConfig.from_pretrained(model_name)\n",
    "#     config.hidden_dropout_prob = 0.1\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_name) # tokenizer\n",
    "#     teacher_model = OPTForCausalLM.from_pretrained(model_name) # teacher model\n",
    "#     student_model = OPTForCausalLM.from_pretrained(model_name, config=config) # student model\n",
    "\n",
    "#     for param in student_model.parameters():\n",
    "#         param.requires_grad = False\n",
    "#         if param.ndim == 1:\n",
    "#             param.data = param.data.to(torch.float32)\n",
    "    \n",
    "#     student_model.gradient_checkpointing_enable()\n",
    "#     student_model.enable_input_require_grads()\n",
    "#     student_model.lm_head = CastOutputToFloat(student_model.lm_head)\n",
    "\n",
    "#     config = LoraConfig(\n",
    "#         r=16,\n",
    "#         lora_alpha=32,\n",
    "#         lora_dropout=0.05,\n",
    "#         bias=\"none\",\n",
    "#         task_type=\"CAUSAL_LM\"\n",
    "#     )\n",
    "    \n",
    "#     student_model = get_peft_model(student_model, config)\n",
    "#     return tokenizer, student_model, teacher_model\n",
    "\n",
    "# def get_dataset(data_set_used):\n",
    "#     datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "    \n",
    "#     if data_set_used in ['mnli', 'rte', 'hans']:\n",
    "#         teacher_prompt = 'Think logically. Are the following sentences examples of entailment, yes or no?'\n",
    "#         student_prompt = 'Are the following sentences examples of entailment, yes or no?'\n",
    "#     elif data_set_used in ['qqp', 'paws-qqp']:\n",
    "#         teacher_prompt = 'Think logically. Are the following sentences duplicates or paraphrases of each other, yes or no?'\n",
    "#         student_prompt = 'Are the following sentences duplicates or paraphrases of each other, yes or no?'\n",
    "\n",
    "#     return datasets, labels, num_labels, teacher_prompt, student_prompt\n",
    "    \n",
    "# # Assuming `losses` is the list of epoch losses returned from the `train` function\n",
    "# def plot_losses(losses):\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.plot(losses, marker='o', linestyle='-', color='b')\n",
    "#     plt.title('Training Loss Per Epoch')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Average Loss')\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "# def train(teacher_model, student_model, data, epochs=10, batch_size=32, device='cpu'):\n",
    "#     student_model.to(device)\n",
    "#     teacher_model.to(device)\n",
    "#     print(id(student_model))\n",
    "#     print(id(teacher_model))\n",
    "    \n",
    "#     student_model.train()\n",
    "#     optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-5, weight_decay=0.000001 )\n",
    "#     epoch_losses = []\n",
    "\n",
    "#     if (len(data) % batch_size != 0):\n",
    "#         num_batches = (len(data) // batch_size) + 1\n",
    "#     else:\n",
    "#         num_batches  = len(data) // batch_size\n",
    "\n",
    "#     num_datapoints = len(data)\n",
    "#     total_steps = num_batches * epochs\n",
    "#     warmup_ratio = int(0.1 * total_steps) \n",
    "    \n",
    "#     def lr_schedular(current_step: int):\n",
    "#         if current_step < warmup_ratio:\n",
    "#             return float(current_step) / float(max(1,warmup_ratio))\n",
    "#         return 1.\n",
    "    \n",
    "#     scheduler = LambdaLR(optimizer, lr_schedular)\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         total_loss = 0\n",
    "#         samples_left = num_datapoints\n",
    "        \n",
    "#         for i in range(num_batches):\n",
    "#             batch_loss = 0\n",
    "#             if ((samples_left - batch_size) >= 0):\n",
    "#                 samples_used = batch_size\n",
    "#                 samples_left -= batch_size\n",
    "#             else:\n",
    "#                 samples_used = samples_left\n",
    "#                 samples_left = 0\n",
    "#             for j in range(samples_used):\n",
    "#                 index = i * batch_size + j\n",
    "                \n",
    "#                 teacher_inputs = data[index]['context'].to(device)\n",
    "#                 student_inputs = data[index]['query'].to(device)\n",
    "                                \n",
    "#                 teacher_outputs = teacher_model.generate(\n",
    "#                     **teacher_inputs,\n",
    "#                     max_length=teacher_inputs['input_ids'].shape[-1] + 1,\n",
    "#                     output_scores=True,\n",
    "#                     return_dict_in_generate=True\n",
    "#                 )\n",
    "#                 teacher_probs = torch.nn.functional.softmax(teacher_outputs.scores[0], dim=-1)\n",
    "                \n",
    "#                 student_logits = student_model(**student_inputs).logits\n",
    "#                 student_probs = torch.nn.functional.softmax(student_logits[:, -1, :], dim=-1)\n",
    "                \n",
    "#                 kl_divergence = torch.nn.functional.kl_div(student_probs.log(), teacher_probs, reduction='batchmean')\n",
    "                \n",
    "#                 optimizer.zero_grad()\n",
    "#                 kl_divergence.backward()\n",
    "#                 optimizer.step()\n",
    "\n",
    "#                 batch_loss += kl_divergence.item()\n",
    "\n",
    "#             # Average loss for the batch\n",
    "#             batch_loss /= batch_size\n",
    "#             total_loss += batch_loss\n",
    "#             scheduler.step()\n",
    "#             #print(f\"Epoch {epoch + 1}, Batch {i + 1}, Average Loss: {batch_loss}\")\n",
    "\n",
    "\n",
    "#         # Average loss for the epoch\n",
    "#         epoch_loss = total_loss / num_batches\n",
    "#         epoch_losses.append(epoch_loss)\n",
    "\n",
    "#         print(f\"Epoch {epoch + 1}, Total Loss: {epoch_loss}\")\n",
    "        \n",
    "#     print(f\"Total loss : {total_loss/epochs}\")\n",
    "#     plot_losses(epoch_losses)\n",
    "#     # torch.save(student_model, './models/student.pth')\n",
    "\n",
    "# def predict(model, source, target=None, device='cpu'):\n",
    "#     predict = []\n",
    "#     for token in source:\n",
    "#         output = model.generate(**token, max_length=token['input_ids'].shape[-1] + 1).to(device)\n",
    "#         decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "#         predicted_label = decoded_output.split(\"Label:\")[-1].strip().split('.')[0].strip()\n",
    "#         predict.append(predicted_label)\n",
    "        \n",
    "#     return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a750150-12ce-4d60-8cb9-3ef580899e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_job(dataset_used, model_name, epochs, val_len, train_len, context_len, seed):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    datasets, labels, num_labels, teacher_prompt, student_prompt = get_dataset(data_set_used)\n",
    "    \n",
    "    set_seed(seed)\n",
    "    print('starting run: {}'.format(seed))\n",
    "    print('loading model')\n",
    "    tokenizer, student_model, teacher_model = get_model(model_name)\n",
    "    print(\"finished loading model\")\n",
    "    \n",
    "    print(\"predicting on validation set\")\n",
    "    student_prompt_tokens, student_prompt_strings, val_indices, val_labels = create_validation_batch_token(\n",
    "        dataset_used, datasets, prompt_descr=student_prompt ,tokenizer=tokenizer, device=device, limit=100\n",
    "    )\n",
    "    prediction = predict(student_model, student_prompt_tokens, tokenizer = tokenizer, device=device)  \n",
    "    print(\"finished predicting on validation set\")\n",
    "\n",
    "    accuracy = accuracy_score(prediction,val_labels)\n",
    "    print(\"finished run {}\".format(seed))\n",
    "    print(\"final result\",accuracy)\n",
    "\n",
    "    if not os.path.exists('output'):\n",
    "        os.makedirs('output')\n",
    "        \n",
    "    meta_data_file_name = f'pre_training_{dataset_used}_{model_name}_{seed}_{epochs}_{val_len}_{train_len}_{context_len}.json'\n",
    "    metadata_loc = os.path.join('output',meta_data_file_name)\n",
    "    metadata = {\n",
    "        'accuracy': accuracy,\n",
    "        'query_indices': indices,\n",
    "        'context_indices': context_indices.tolist(),\n",
    "        'validation_indices': val_indices.tolist(),\n",
    "        'model_name': model_name,\n",
    "        'dataset_used': dataset_used,\n",
    "        'seed': seed,\n",
    "        'epochs': epochs,\n",
    "        'val_len': val_len,\n",
    "        'train_len': train_len,\n",
    "        'context_len': context_len\n",
    "    }\n",
    "    \n",
    "    with open(metadata_loc, 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd48760-4f90-44ad-a4dc-f0d738a3dadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTED\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTARTED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(runs):\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mrun_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_set_used\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFINISHED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36mrun_job\u001b[1;34m(dataset_used, model_name, epochs, val_len, train_len, context_len, seed)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_job\u001b[39m(dataset_used, model_name, epochs, val_len, train_len, context_len, seed):\n\u001b[0;32m      2\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     datasets, labels, num_labels, teacher_prompt, student_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m(data_set_used)\n\u001b[0;32m      5\u001b[0m     set_seed(seed)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarting run: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(seed))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "runs = 10\n",
    "data_set_used = 'rte'\n",
    "model_name = \"opt-125m\"\n",
    "epochs = 40\n",
    "val_len = 1000\n",
    "train_len = 128\n",
    "context_len = 16\n",
    "\n",
    "print(\"STARTED\")\n",
    "for seed in range(runs):\n",
    "    run_job(data_set_used,model_name,epochs,val_len, train_len, context_len,seed)\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d417f9-0537-4ea3-80a7-85517a6da87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
