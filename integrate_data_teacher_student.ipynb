{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import OPTForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from data_utils import (\n",
    "    load_glue_datasets,\n",
    "    load_hans_dataset,\n",
    "    load_paws_qqp_dataset,\n",
    ")\n",
    "from context_utils import create_few_shot_context, select_demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer + Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\") # tokenizer\n",
    "teacher_model = OPTForCausalLM.from_pretrained(\"facebook/opt-125m\") # teacher model\n",
    "student_model = OPTForCausalLM.from_pretrained(\"facebook/opt-125m\") # student model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_used='mnli'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "\n",
    "if data_set_used in ['mnli', 'rte', 'hans']:\n",
    "    teacher_prompt = 'Think logically. Are the following sentences examples of entailment, yes or no?'\n",
    "    student_prompt = 'Are the following sentences examples of entailment, yes or no?'\n",
    "elif data_set_used in ['qqp', 'paws-qqp']:\n",
    "    teacher_prompt = 'Think logically. Are the following sentences duplicates or paraphrases of each other, yes or no?'\n",
    "    student_prompt = 'Are the following sentences duplicates or paraphrases of each other, yes or no?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_batch_token(\n",
    "    dataset_name,\n",
    "    datasets,\n",
    "    tokenizer,\n",
    "    num_shots=16,\n",
    "    device = 'cpu',\n",
    "    num_sets=15,\n",
    "    teacher_descr=teacher_prompt,\n",
    "    student_descr=student_prompt\n",
    "):\n",
    "    datasets = datasets['train']\n",
    "    \n",
    "    batch_tokens = []\n",
    "    batch_strings = []\n",
    "    \n",
    "    all_indices = []\n",
    "    seed_nums = [randint(0, 1000) for i in range(num_sets)]\n",
    "    for sn in seed_nums:\n",
    "        # Randomly select demonstrations\n",
    "        demonstrations, indices = select_demonstrations(\n",
    "            datasets,\n",
    "            balanced=True,\n",
    "            rand_subset=True,\n",
    "            num_shots=num_shots,\n",
    "            seed=sn,\n",
    "        )\n",
    "        context, student_context = create_few_shot_context(\n",
    "            dataset_name,\n",
    "            demonstrations,\n",
    "            datasets.features['label'],\n",
    "            teacher_description=teacher_descr,\n",
    "            student_description=student_descr,\n",
    "        )\n",
    "        token_data= {\n",
    "            'context':(tokenizer(context, return_tensors=\"pt\")).to(device),\n",
    "            'query':(tokenizer(student_context, return_tensors=\"pt\")).to(device)\n",
    "        }\n",
    "        string_data = {\n",
    "            'context':context,\n",
    "            'query':student_context\n",
    "        }\n",
    "        batch_tokens.append(token_data)\n",
    "        batch_strings.append(string_data)\n",
    "        all_indices.extend(indices)\n",
    "        \n",
    "        # Select demonstrations by index and shuffle them\n",
    "        shuffled_demo, _ = select_demonstrations(\n",
    "            datasets,\n",
    "            shuffle=True,\n",
    "            from_idxlabels=indices,\n",
    "        )\n",
    "        shuffled_context, shuffled_student_context = create_few_shot_context(\n",
    "            dataset_name,\n",
    "            shuffled_demo,\n",
    "            datasets.features['label'],\n",
    "            teacher_description=teacher_descr,\n",
    "            student_description=student_descr,\n",
    "        )\n",
    "        token_data= {\n",
    "            'context':(tokenizer(shuffled_context, return_tensors=\"pt\")).to(device),\n",
    "            'query':(tokenizer(shuffled_student_context, return_tensors=\"pt\")).to(device)\n",
    "        }\n",
    "        string_data = {\n",
    "            'context':shuffled_context,\n",
    "            'query':shuffled_student_context\n",
    "        }\n",
    "        batch_tokens.append(token_data)\n",
    "        batch_strings.append(string_data)\n",
    "        all_indices.extend(indices)\n",
    "\n",
    "    return batch_tokens, batch_strings, all_indices\n",
    "\n",
    "def create_validation_batch_token(\n",
    "    dataset_name,\n",
    "    datasets,\n",
    "    tokenizer,\n",
    "    device = 'cpu',\n",
    "    prompt_descr=student_prompt,\n",
    "    limit=10\n",
    "):\n",
    "    if dataset_name == 'mnli':\n",
    "        split = 'validation_matched'\n",
    "    else:\n",
    "        split = 'validation'\n",
    "        \n",
    "    datasets = datasets[split]\n",
    "    \n",
    "    demonstrations, all_indices = select_demonstrations(datasets)\n",
    "    batch_tokens = []\n",
    "    batch_strings = []\n",
    "    for dx in range(limit):\n",
    "        context, _ = create_few_shot_context(\n",
    "            dataset_name,\n",
    "            [demonstrations[dx]],\n",
    "            demonstrations.features['label'],\n",
    "            teacher_description=prompt_descr,\n",
    "            remove_label=True\n",
    "        )\n",
    "        token_data = (tokenizer(context, return_tensors=\"pt\")).to(device)\n",
    "        batch_tokens.append(token_data)\n",
    "        batch_strings.append(context)\n",
    "    return batch_tokens, batch_strings, all_indices[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ed1f49ae1841f2a8013666d4cfaef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3719fccac4448289b566687ea3f8f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f1c171088f453b9b8c711372cf4cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c7b30270c6484baa340b826a43501d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644b006fbd2b452e932a0f471b462634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3517a503a754faba65b238b4ff5cc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f310e63bb5374862bcf76a134afe642c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a237ea6b96450c80dd1d231818c58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125d8add5fff43618702cc95badbbdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba7ceb480ea4304abdac436d43c7dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53a7c782c20427ebae4c917df6f5c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f50d460e17428aa0787d0f5bace2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5605800f09724ab0a9ad988dd5da73a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374fc4e656df40508f6bcdb12a6f8b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99285e2c72934c54a154de3ffc4ce8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790aa9ee9f9342e2a1c0bd53282ab16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4aee09c90ff434781e4289149852818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3cb429385b423c84615c9be5c6895b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84bcf502dac47f5b7cdcf05afc6d7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5567a39b8f465bbcbea00c201dc78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba1196eadc245e1bfa1371fbed48494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4158ac3ba1c5446a9e8a03df608fb1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b902067766c849449478c7d38c3b67fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3caa092c1134c9ca012ac79f13af5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df56c247e93d4bd488d51731c33cd39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c0610343cc41de97287a3446b73f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1473b255d14aff99be52d62db3dced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be7c0be9e754f2aa80d41dd087e9116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_tokens, train_data_strings, _ = create_train_batch_token(\n",
    "    data_set_used, datasets, tokenizer=tokenizer, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `losses` is the list of epoch losses returned from the `train` function\n",
    "def plot_losses(losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Training Loss Per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Total Loss: 1.8366981307044625\n",
      "Epoch 2, Total Loss: 0.352981100557372\n",
      "Epoch 3, Total Loss: 0.1853049547644332\n",
      "Epoch 4, Total Loss: 0.14986625174060464\n",
      "Epoch 5, Total Loss: 0.14878475072328\n",
      "Epoch 6, Total Loss: 0.15721535589545965\n"
     ]
    }
   ],
   "source": [
    "def train(data, epochs=10, batch_size=16, device='cpu'):\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    \n",
    "    student_model.train()\n",
    "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=0.001)\n",
    "    epoch_losses = []\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        num_batches = len(data) // batch_size \n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            batch_loss = 0\n",
    "            for j in range(batch_size):\n",
    "                index = i * batch_size + j\n",
    "                \n",
    "                teacher_inputs = data[index]['context'].to(device)\n",
    "                student_inputs = data[index]['query'].to(device)\n",
    "                                \n",
    "                teacher_outputs = teacher_model.generate(\n",
    "                    **teacher_inputs,\n",
    "                    max_length=teacher_inputs['input_ids'].shape[-1] + 1,\n",
    "                    output_scores=True,\n",
    "                    return_dict_in_generate=True\n",
    "                )\n",
    "                teacher_probs = torch.nn.functional.softmax(teacher_outputs.scores[0], dim=-1)\n",
    "                \n",
    "                student_logits = student_model(**student_inputs).logits\n",
    "                student_probs = torch.nn.functional.softmax(student_logits[:, -1, :], dim=-1)\n",
    "                \n",
    "                kl_divergence = torch.nn.functional.kl_div(student_probs.log(), teacher_probs, reduction='batchmean')\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                kl_divergence.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_loss += kl_divergence.item()\n",
    "\n",
    "            # Average loss for the batch\n",
    "            batch_loss /= batch_size\n",
    "            total_loss += batch_loss\n",
    "            # print(f\"Epoch {epoch + 1}, Batch {i + 1}, Average Loss: {batch_loss}\")\n",
    "\n",
    "\n",
    "        # Average loss for the epoch\n",
    "        epoch_loss = total_loss / num_batches\n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Total Loss: {epoch_loss}\")\n",
    "        \n",
    "    print(f\"Total loss : {total_loss/epochs}\")\n",
    "    plot_losses(epoch_losses)\n",
    "    # torch.save(student_model, './models/student.pth')\n",
    "\n",
    "\n",
    "train(train_data_tokens, epochs = 40, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, source, target=None, device='cpu'):\n",
    "    predict = []\n",
    "    for token in source:\n",
    "        output = model.generate(**token, max_length=token['input_ids'].shape[-1] + 1).to(device)\n",
    "        decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        predicted_label = decoded_output.split(\"Label:\")[-1].strip().split('.')[0].strip()\n",
    "        predict.append(predicted_label)\n",
    "        \n",
    "    return predict\n",
    "\n",
    "\n",
    "student_prompt_tokens, student_prompt_strings, all_indices = create_validation_batch_token(\n",
    "    data_set_used, datasets, tokenizer=tokenizer, device=device, limit=10\n",
    ")\n",
    "prediction = predict(student_model, student_prompt_tokens, device=device)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [datasets['validation_matched']['label'][datasets['validation_matched']['idx'].index(i)] for i in all_indices]\n",
    "labels = datasets['validation_matched'].features['label'].int2str(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([(a == b) * 1 for a, b in zip(labels,prediction)]) / 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
