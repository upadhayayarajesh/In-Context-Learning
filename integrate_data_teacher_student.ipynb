{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import OPTForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from data_utils import (\n",
    "    load_glue_datasets,\n",
    "    load_hans_dataset,\n",
    "    load_paws_qqp_dataset,\n",
    ")\n",
    "from context_utils import create_few_shot_context, select_demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer + Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\") # tokenizer\n",
    "teacher_model = OPTForCausalLM.from_pretrained(\"facebook/opt-125m\") # teacher model\n",
    "student_model = OPTForCausalLM.from_pretrained(\"facebook/opt-125m\") # student model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_used='mnli'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "\n",
    "if data_set_used in ['mnli', 'rte', 'hans']:\n",
    "    teacher_prompt = 'Think logically. Are the following sentences examples of entailment, yes or no?'\n",
    "    student_prompt = 'Are the following sentences examples of entailment, yes or no?'\n",
    "elif data_set_used in ['qqp', 'paws-qqp']:\n",
    "    teacher_prompt = 'Think logically. Are the following sentences duplicates or paraphrases of each other, yes or no?'\n",
    "    student_prompt = 'Are the following sentences duplicates or paraphrases of each other, yes or no?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_batch_token(\n",
    "    dataset_name,\n",
    "    datasets,\n",
    "    tokenizer,\n",
    "    num_shots=16,\n",
    "    device = 'cpu',\n",
    "    num_sets=15,\n",
    "    teacher_descr=teacher_prompt,\n",
    "    student_descr=student_prompt\n",
    "):\n",
    "    datasets = datasets['train']\n",
    "    \n",
    "    batch_tokens = []\n",
    "    batch_strings = []\n",
    "    \n",
    "    all_indices = []\n",
    "    seed_nums = [randint(0, 1000) for i in range(num_sets)]\n",
    "    for sn in seed_nums:\n",
    "        # Randomly select demonstrations\n",
    "        demonstrations, indices = select_demonstrations(\n",
    "            datasets,\n",
    "            balanced=True,\n",
    "            rand_subset=True,\n",
    "            num_shots=num_shots,\n",
    "            seed=sn,\n",
    "        )\n",
    "        context, student_context = create_few_shot_context(\n",
    "            dataset_name,\n",
    "            demonstrations,\n",
    "            datasets.features['label'],\n",
    "            teacher_description=teacher_descr,\n",
    "            student_description=student_descr,\n",
    "        )\n",
    "        token_data= {\n",
    "            'context':(tokenizer(context, return_tensors=\"pt\")).to(device),\n",
    "            'query':(tokenizer(student_context, return_tensors=\"pt\")).to(device)\n",
    "        }\n",
    "        string_data = {\n",
    "            'context':context,\n",
    "            'query':student_context\n",
    "        }\n",
    "        batch_tokens.append(token_data)\n",
    "        batch_strings.append(string_data)\n",
    "        all_indices.extend(indices)\n",
    "        \n",
    "        # Select demonstrations by index and shuffle them\n",
    "        shuffled_demo, _ = select_demonstrations(\n",
    "            datasets,\n",
    "            shuffle=True,\n",
    "            from_idxlabels=indices,\n",
    "        )\n",
    "        shuffled_context, shuffled_student_context = create_few_shot_context(\n",
    "            dataset_name,\n",
    "            shuffled_demo,\n",
    "            datasets.features['label'],\n",
    "            teacher_description=teacher_descr,\n",
    "            student_description=student_descr,\n",
    "        )\n",
    "        token_data= {\n",
    "            'context':(tokenizer(shuffled_context, return_tensors=\"pt\")).to(device),\n",
    "            'query':(tokenizer(shuffled_student_context, return_tensors=\"pt\")).to(device)\n",
    "        }\n",
    "        string_data = {\n",
    "            'context':shuffled_context,\n",
    "            'query':shuffled_student_context\n",
    "        }\n",
    "        batch_tokens.append(token_data)\n",
    "        batch_strings.append(string_data)\n",
    "        all_indices.extend(indices)\n",
    "\n",
    "    return batch_tokens, batch_strings, all_indices\n",
    "\n",
    "def create_validation_batch_token(\n",
    "    dataset_name,\n",
    "    datasets,\n",
    "    tokenizer,\n",
    "    device = 'cpu',\n",
    "    prompt_descr=student_prompt,\n",
    "    limit=10\n",
    "):\n",
    "    if dataset_name == 'mnli':\n",
    "        split = 'validation_matched'\n",
    "    else:\n",
    "        split = 'validation'\n",
    "        \n",
    "    datasets = datasets[split]\n",
    "    \n",
    "    demonstrations, all_indices = select_demonstrations(datasets)\n",
    "    \n",
    "    batch_tokens = []\n",
    "    batch_strings = []\n",
    "    for dx in range(limit):\n",
    "        context, _ = create_few_shot_context(\n",
    "            dataset_name,\n",
    "            [demonstrations[dx]],\n",
    "            demonstrations.features['label'],\n",
    "            teacher_description=prompt_descr,\n",
    "            remove_label=True\n",
    "        )\n",
    "        token_data = (tokenizer(context, return_tensors=\"pt\")).to(device)\n",
    "        batch_tokens.append(token_data)\n",
    "        batch_strings.append(context)\n",
    "    return batch_tokens, batch_strings, all_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc65472fa0f44892a7e706fd6cc421cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0ff347f0b74ca58b94d8b91e3b6924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1101d9669f4e53a49007bd7e1a9a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fe68d3ff074268a707904eeace4d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d1cb23542246d3b1554dfbb4a8d344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c54485b8a24bc98345fcd77bdf90a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9063824502641dbbfa5d147f65c2e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b85de88ba446a8afa825b109d3ea82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50a796f0a274d1b80a2569bac60cb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e1049acd8b43a6b961141e31f47409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a5a2561a2f41fa9370479a0488fd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db8170a59ab4cf8838f8939243b18c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c395d1775b5467a9cd5219825b9926b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba6459a85474d77b10373cc24ceb279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72afc36ecb34c39adc752f82c61c169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/261802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_tokens, train_data_strings, _ = create_train_batch_token(\n",
    "    data_set_used, datasets, tokenizer=tokenizer, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `losses` is the list of epoch losses returned from the `train` function\n",
    "def plot_losses(losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Training Loss Per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Total Loss: 1.2737659368819247\n",
      "Epoch 2, Total Loss: 0.2252691303147003\n",
      "Epoch 3, Total Loss: 0.20373394584748894\n",
      "Epoch 4, Total Loss: 0.22771672343757624\n",
      "Epoch 5, Total Loss: 0.16852308080221215\n",
      "Epoch 6, Total Loss: 0.1393041613822182\n",
      "Epoch 7, Total Loss: 0.1435140419829016\n",
      "Epoch 8, Total Loss: 0.12100305792409927\n",
      "Epoch 9, Total Loss: 0.11889214836992323\n"
     ]
    }
   ],
   "source": [
    "def train(data, epochs=10, batch_size=16, device='cpu'):\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    \n",
    "    student_model.train()\n",
    "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=0.001)\n",
    "    epoch_losses = []\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        num_batches = len(data) // batch_size \n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            batch_loss = 0\n",
    "            for j in range(batch_size):\n",
    "                index = i * batch_size + j\n",
    "                \n",
    "                teacher_inputs = data[index]['context'].to(device)\n",
    "                student_inputs = data[index]['query'].to(device)\n",
    "                                \n",
    "                teacher_outputs = teacher_model.generate(\n",
    "                    **teacher_inputs,\n",
    "                    max_length=teacher_inputs['input_ids'].shape[-1] + 1,\n",
    "                    output_scores=True,\n",
    "                    return_dict_in_generate=True\n",
    "                )\n",
    "                teacher_probs = torch.nn.functional.softmax(teacher_outputs.scores[0], dim=-1)\n",
    "                \n",
    "                student_logits = student_model(**student_inputs).logits\n",
    "                student_probs = torch.nn.functional.softmax(student_logits[:, -1, :], dim=-1)\n",
    "                \n",
    "                kl_divergence = torch.nn.functional.kl_div(student_probs.log(), teacher_probs, reduction='batchmean')\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                kl_divergence.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_loss += kl_divergence.item()\n",
    "\n",
    "            # Average loss for the batch\n",
    "            batch_loss /= batch_size\n",
    "            total_loss += batch_loss\n",
    "            # print(f\"Epoch {epoch + 1}, Batch {i + 1}, Average Loss: {batch_loss}\")\n",
    "\n",
    "\n",
    "        # Average loss for the epoch\n",
    "        epoch_loss = total_loss / num_batches\n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Total Loss: {epoch_loss}\")\n",
    "        \n",
    "    print(f\"Total loss : {total_loss/epochs}\")\n",
    "    plot_losses(epoch_losses)\n",
    "    # torch.save(student_model, './models/student.pth')\n",
    "\n",
    "\n",
    "train(train_data_tokens, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, source, target=None, device='cpu'):\n",
    "    predict = []\n",
    "    for token in source:\n",
    "        output = model.generate(**token, max_length=token['input_ids'].shape[-1] + 1).to(device)\n",
    "        decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        predicted_label = decoded_output.split(\"Label:\")[-1].strip().split('.')[0].strip()\n",
    "        predict.append(predicted_label)\n",
    "        \n",
    "    return predict\n",
    "\n",
    "\n",
    "student_prompt_tokens, student_prompt_strings, all_indices = create_validation_batch_token(\n",
    "    data_set_used, datasets, tokenizer=tokenizer, device=device, limit=10\n",
    ")\n",
    "prediction = predict(student_model, student_prompt_tokens, device=device)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student input: Are the following sentences examples of entailment, yes or no?\n",
      "\n",
      "Premise: It's come back? cried Julius excitedly.,\n",
      "Hypothesis: News of it being gone left them devastated. ,\n",
      "Label:\n",
      "\n",
      "\n",
      "Student output: Are the following sentences examples of entailment, yes or no?\n",
      "\n",
      "Premise: It's come back? cried Julius excitedly.,\n",
      "Hypothesis: News of it being gone left them devastated.,\n",
      "Label: \"\n"
     ]
    }
   ],
   "source": [
    "# # Use for testing\n",
    "# ind = 66\n",
    "# student_inputs = student_prompt_tokens[ind].to(device)\n",
    "\n",
    "# student_outputs = student_model.generate(\n",
    "#     **student_inputs,\n",
    "#     max_length=student_inputs['input_ids'].shape[-1] + 1\n",
    "# ).to(device)\n",
    "# decoded_output = tokenizer.decode(student_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# print(f\"Student input: {student_prompt_strings[ind]}\")\n",
    "# print('\\n')\n",
    "# print(f\"Student output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [datasets['validation_matched']['label'][datasets['validation_matched']['idx'].index(i)] for i in all_indices]\n",
    "labels = datasets['validation_matched'].features['label'].int2str(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([ (l == p) * 1 for l,p in zip(labels,prediction) ]) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlproject-3.12.2",
   "language": "python",
   "name": "dlproject-3.12.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
