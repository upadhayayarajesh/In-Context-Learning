{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import OPTForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from data_utils import (\n",
    "    load_glue_datasets,\n",
    "    load_hans_dataset,\n",
    "    load_paws_qqp_dataset,\n",
    ")\n",
    "from context_utils import create_few_shot_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer + Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\") # tokenizer\n",
    "teacher_model = OPTForCausalLM.from_pretrained(\"facebook/opt-125m\") # teacher model\n",
    "student_model = OPTForCausalLM.from_pretrained(\"facebook/opt-125m\") # student model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_used='mnli'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "\n",
    "if data_set_used in ['mnli', 'rte', 'hans']:\n",
    "    teacher_prompt = 'Think logically. Are the following sentences examples of entailment, yes or no?'\n",
    "    student_prompt = 'Are the following sentences examples of entailment, yes or no?'\n",
    "elif data_set_used in ['qqp', 'paws-qqp']:\n",
    "    teacher_prompt = 'Think logically. Are the following sentences duplicates or paraphrases of each other, yes or no?'\n",
    "    student_prompt = 'Are the following sentences duplicates or paraphrases of each other, yes or no?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_token(\n",
    "    dataset_name,\n",
    "    datasets,\n",
    "    tokenizer,\n",
    "    num_shots=1,\n",
    "    device = 'cpu',\n",
    "    split='train',\n",
    "    len_subset=300,\n",
    "    teacher_descr=teacher_prompt,\n",
    "    student_descr=student_prompt\n",
    "):\n",
    "    batch_tokens = []\n",
    "    batch_strings = []\n",
    "    datasets = datasets[split]\n",
    "    all_indices = []\n",
    "    seed_num = 0\n",
    "    for i in range(0, len_subset, num_shots):\n",
    "        if split == 'train':\n",
    "            context, student_context, indices = create_few_shot_context(\n",
    "                dataset_name,\n",
    "                datasets,\n",
    "                num_shots,\n",
    "                teacher_description=teacher_descr,\n",
    "                student_description=student_descr,\n",
    "                balanced=True,\n",
    "                seed = seed_num\n",
    "            )\n",
    "            token_data= {\n",
    "                'context':(tokenizer(context, return_tensors=\"pt\")).to(device),\n",
    "                'query':(tokenizer(student_context, return_tensors=\"pt\")).to(device)\n",
    "            }\n",
    "            string_data = {\n",
    "                'context':context,\n",
    "                'query':student_context\n",
    "            }\n",
    "        else:\n",
    "            context, student_context, indices = create_few_shot_context(\n",
    "                dataset_name,\n",
    "                datasets,\n",
    "                num_shots,\n",
    "                student_description=student_descr,\n",
    "                seed = seed_num\n",
    "            )\n",
    "            token_data = (tokenizer(student_context, return_tensors=\"pt\")).to(device)\n",
    "            string_data = student_context\n",
    "        batch_tokens.append(token_data)\n",
    "        batch_strings.append(string_data)\n",
    "        all_indices.extend(indices)\n",
    "        seed_num += 1\n",
    "    return batch_tokens, batch_strings, all_indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tokens, train_data_strings, _ = create_batch_token(\n",
    "    data_set_used, datasets, num_shots=6, tokenizer=tokenizer, device=device\n",
    ")\n",
    "student_prompt_tokens, student_prompt_strings, _ = create_batch_token(\n",
    "    data_set_used, datasets, num_shots=1, tokenizer=tokenizer, device=device, split= 'validation_matched'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `losses` is the list of epoch losses returned from the `train` function\n",
    "def plot_losses(losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Training Loss Per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, epochs=10, batch_size=16, device='cpu'):\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    \n",
    "    student_model.train()\n",
    "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=0.001)\n",
    "    epoch_losses = []\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        num_batches = len(data) // batch_size \n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            batch_loss = 0\n",
    "            for j in range(batch_size):\n",
    "                index = i * batch_size + j\n",
    "                \n",
    "                teacher_inputs = data[index]['context'].to(device)\n",
    "                student_inputs = data[index]['query'].to(device)\n",
    "                                \n",
    "                teacher_outputs = teacher_model.generate(\n",
    "                    **teacher_inputs,\n",
    "                    max_length=teacher_inputs['input_ids'].shape[-1] + 1,\n",
    "                    output_scores=True,\n",
    "                    return_dict_in_generate=True\n",
    "                )\n",
    "                teacher_probs = torch.nn.functional.softmax(teacher_outputs.scores[0], dim=-1)\n",
    "                \n",
    "                student_logits = student_model(**student_inputs).logits\n",
    "                student_probs = torch.nn.functional.softmax(student_logits[:, -1, :], dim=-1)\n",
    "                \n",
    "                kl_divergence = torch.nn.functional.kl_div(student_probs.log(), teacher_probs, reduction='batchmean')\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                kl_divergence.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_loss += kl_divergence.item()\n",
    "\n",
    "            # Average loss for the batch\n",
    "            batch_loss /= batch_size\n",
    "            total_loss += batch_loss\n",
    "            # print(f\"Epoch {epoch + 1}, Batch {i + 1}, Average Loss: {batch_loss}\")\n",
    "\n",
    "\n",
    "        # Average loss for the epoch\n",
    "        epoch_loss = total_loss / num_batches\n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Total Loss: {epoch_loss}\")\n",
    "        \n",
    "    print(f\"Total loss : {total_loss/epochs}\")\n",
    "    plot_losses(epoch_losses)\n",
    "    # torch.save(student_model, './models/student.pth')\n",
    "\n",
    "\n",
    "train(train_data_tokens, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, source, target=None, device='cpu'):\n",
    "    predict = []\n",
    "    for token in source:\n",
    "        output = model.generate(**token, max_length=token['input_ids'].shape[-1] + 1).to(device)\n",
    "        decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        predicted_label = decoded_output.split(\"Label:\")[-1].strip().split('.')[0].strip()\n",
    "        predict.append(predicted_label)\n",
    "        \n",
    "    return predict\n",
    "\n",
    "student_prompt_tokens, student_prompt_strings, all_indices = create_batch_token(\n",
    "    data_set_used, datasets, num_shots=1, tokenizer=tokenizer, device=device, split='validation_matched'\n",
    "    )\n",
    "prediction = predict(student_model, student_prompt_tokens, device=device)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use for testing\n",
    "# ind = 1\n",
    "# student_inputs = student_prompt_tokens[ind].to(device)\n",
    "\n",
    "# student_outputs = student_model.generate(\n",
    "#     **student_inputs,\n",
    "#     max_length=student_inputs['input_ids'].shape[-1] + 1\n",
    "# ).to(device)\n",
    "# decoded_output = tokenizer.decode(student_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# print(f\"Student input: {student_prompt_strings[ind]}\")\n",
    "# print('\\n')\n",
    "# print(f\"Student output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [datasets['validation_matched']['label'][datasets['validation_matched']['idx'].index(i)] for i in all_indices]\n",
    "labels = datasets['validation_matched'].features['label'].int2str(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([ (l == p) * 1 for l,p in zip(labels,prediction) ]) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
