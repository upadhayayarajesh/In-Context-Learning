{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e758257-7597-4cac-a45c-1950972b4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import load_glue_datasets,\\\n",
    "    load_hans_dataset,\\\n",
    "    load_mnli_mismatched_dataset,\\\n",
    "    load_paws_qqp_dataset,\\\n",
    "    load_cola_ood_dataset,\\\n",
    "    task_to_keys\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e07b40-fd9b-433b-9a77-0eb3034eb23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_subset_by_ids(dataset, indices): # indices is a list or np array here...\n",
    "    subset = dataset.select(indices)\n",
    "    return subset\n",
    "\n",
    "def _select_subset_by_idx(dataset, indices):\n",
    "    dataset = dataset.filter(\n",
    "        lambda s: s[\"idx\"] in indices)\n",
    "    return dataset\n",
    "\n",
    "def get_balanced_subsets(dataset):\n",
    "    subset_per_label = {}\n",
    "    for label_idx, _ in enumerate(dataset.features[\"label\"].names):\n",
    "        subset_per_label[label_idx] = dataset.filter(\n",
    "            lambda s: s[\"label\"] == label_idx)\n",
    "    return subset_per_label\n",
    "\n",
    "def _select_random_subset(dataset, num_shots, balanced=False, seed=123):\n",
    "    # fix seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    if num_shots < 1:\n",
    "        return [], []\n",
    "\n",
    "    if balanced:\n",
    "        assert num_shots % 2 == 0, \"a balanced context requires at least one demonstartion per label\"\n",
    "        # select the same number of samples from every label\n",
    "        indices = []  # we collect all indices here\n",
    "        subset_per_label = get_balanced_subsets(dataset)\n",
    "\n",
    "        for _, samples in subset_per_label.items():\n",
    "            subset_indices = samples[\"idx\"]\n",
    "            # select num_shots // 2 samples\n",
    "            subset_indices = np.random.choice(\n",
    "                subset_indices, size=num_shots // 2, replace=False)\n",
    "            indices += list(subset_indices)\n",
    "        assert len(indices) == num_shots\n",
    "    else:\n",
    "        # just select a random subset of samples\n",
    "        indices = np.random.choice(\n",
    "            dataset['idx'], size=num_shots, replace=False)\n",
    "\n",
    "    # return _select_subset_by_ids(dataset, indices), indices\n",
    "    return _select_subset_by_idx(dataset, indices), indices\n",
    "\n",
    "\n",
    "def create_few_shot_context(\n",
    "    dataset_name,\n",
    "    dataset,\n",
    "    num_shots,\n",
    "    description=\"\",\n",
    "    remove_label=False,\n",
    "    from_indices=None,\n",
    "    balanced=False,\n",
    "    shuffle=False,\n",
    "    seed=123\n",
    "):\n",
    "    separate_description_by=\"\\n\\n\"\n",
    "    # select samples from which the context will be constructed\n",
    "    if from_indices is not None:\n",
    "        demonstrations = _select_subset_by_ids(dataset, from_indices)\n",
    "        indices = np.array(from_indices)\n",
    "    else:\n",
    "        demonstrations, indices = _select_random_subset(\n",
    "            dataset, num_shots, balanced, seed)\n",
    "\n",
    "    if shuffle:\n",
    "        if len(demonstrations) > 0:\n",
    "            demonstrations = demonstrations.shuffle(seed)\n",
    "\n",
    "    # create context\n",
    "    context = \"\" if description == \"\" else f\"{description}{separate_description_by}\"\n",
    "    student_context = \"\" if description == \"\" else f\"{description}{separate_description_by}\"\n",
    "    int_to_label_converter = dataset.features['label']\n",
    "\n",
    "    if task_to_keys[dataset_name][1] is not None:\n",
    "        pattern = '{prefix1}: {text1},\\n{prefix2}: {text2},'\n",
    "    else:\n",
    "        pattern = '{prefix1}: {text1}'\n",
    "    current_shot = num_shots\n",
    "    for sample in demonstrations:\n",
    "        second_key_present = task_to_keys[dataset_name][1]\n",
    "        formated_sample = pattern.format(\n",
    "            prefix1=task_to_keys[dataset_name][0].capitalize(),\n",
    "            text1=sample[task_to_keys[dataset_name][0]],\n",
    "            prefix2=task_to_keys[dataset_name][1].capitalize() if second_key_present is not None else None,\n",
    "            text2=sample[task_to_keys[dataset_name][1]] if second_key_present is not None else None\n",
    "        )\n",
    "        if sample[\"label\"] == -1 or remove_label:\n",
    "            verbalized_label = \"\"\n",
    "        elif current_shot == 1:\n",
    "            verbalized_label =\"\"\n",
    "            student_context += f\"Label if this is entailment or contradiction.\\n\"\n",
    "            student_context += f\"{formated_sample}\\nLabel:{verbalized_label}\"\n",
    "        else:\n",
    "            verbalized_label = int_to_label_converter.int2str(sample[\"label\"])\n",
    "        context += f\"{formated_sample}\\nLabel:{verbalized_label}\"\n",
    "        current_shot -= 1\n",
    "        \n",
    "    return context, student_context, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4c5eb7-e833-4c41-a5ee-5d77ec670bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### rte, mnli, qqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b83f3e44-6dff-41b1-a9ea-5b686f121d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Premise: The Collection and Analysis of Qualitative Data in Evaluation Research.,\\\\nHypothesis: Only quantitative data can be used in evaluation research.,\\\\nLabel: contradictionPremise: The total producer costs estimated by EPA including the costs of certification, addization of the detergents, recordkeeping and enforcement through the year 2000 is almost $704 million.,\\\\nHypothesis: The costs of certification are not included in EPA\\'s total producer costs estimates.,\\\\nLabel: contradictionPremise: If you watch the action closely, you can learn a lot about Indian people by what makes them cheer, laugh, or weep.,\\\\nHypothesis: You can learn a lot about Indian people by watching their actions.,\\\\nLabel: \"'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_used='mnli'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, student_context,  indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['train'],\n",
    "    3\n",
    ")\n",
    "repr(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cb9d961-222a-4a1b-acf5-9111c83c2ad0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m data_set_used\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnli\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m datasets, labels, num_labels \u001b[38;5;241m=\u001b[39m load_glue_datasets(data_set_used)\n\u001b[1;32m----> 3\u001b[0m context, indices \u001b[38;5;241m=\u001b[39m create_few_shot_context(\n\u001b[0;32m      4\u001b[0m     data_set_used,\n\u001b[0;32m      5\u001b[0m     datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_matched\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(context)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "data_set_used='mnli'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['validation_matched'],\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac89f93-2011-44fb-9e78-f36191718ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_used='rte'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['train'],\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce2f27-5d3f-4786-96ba-a4a8c9816334",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_used='rte'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['validation'],\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533cfd5-e38e-4a82-ab97-4cf35add9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_used='qqp'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['train'],\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9f0ee-aef0-44f6-b1f4-7ea90a18ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_used='qqp'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['validation'],\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a948aa2-1943-468d-a13a-d42a6aedccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_used='hans'\n",
    "datasets, subset = load_hans_dataset(heuristic='lexical_overlap')\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets,\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b6e7a-4496-46ac-b000-fc69b6d39811",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_used='paws-qqp'\n",
    "data_path = os.path.join(os.getcwd(),'data')\n",
    "dataset, dataset_name = load_paws_qqp_dataset(path=os.path.join(data_path,'paws_qqp','dev_and_test.tsv'))\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    dataset,\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdcd0ad-04dc-4b79-9ac9-f460a4f27f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
