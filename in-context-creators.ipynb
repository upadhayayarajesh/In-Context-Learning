{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e758257-7597-4cac-a45c-1950972b4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import load_glue_datasets,\\\n",
    "    load_hans_dataset,\\\n",
    "    load_mnli_mismatched_dataset,\\\n",
    "    load_paws_qqp_dataset,\\\n",
    "    load_cola_ood_dataset,\\\n",
    "    task_to_keys\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e07b40-fd9b-433b-9a77-0eb3034eb23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_utils import task_to_keys\n",
    "\n",
    "def get_sample_ids(path):\n",
    "    # we save examples as a .csv file which has an \"idx\" column\n",
    "    df = pd.read_csv(path, sep=\",\", index_col=0)\n",
    "    return df[\"idx\"].values\n",
    "\n",
    "def _select_subset_by_ids(dataset, indices):\n",
    "    subset = dataset.select(indices)\n",
    "    return subset\n",
    "\n",
    "def _select_subset_by_idx(dataset, indices):\n",
    "    dataset = dataset.filter(\n",
    "        lambda s: s[\"idx\"] in indices)\n",
    "    return dataset\n",
    "\n",
    "def get_balanced_subsets(dataset):\n",
    "    subset_per_label = {}\n",
    "    for label_idx, _ in enumerate(dataset.features[\"label\"].names):\n",
    "        subset_per_label[label_idx] = dataset.filter(\n",
    "            lambda s: s[\"label\"] == label_idx)\n",
    "    return subset_per_label\n",
    "\n",
    "def _select_random_subset(dataset, num_shots, balanced=False, seed=123):\n",
    "    # fix seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    if num_shots < 1:\n",
    "        return [], []\n",
    "\n",
    "    if balanced:\n",
    "        assert num_shots % 2 == 0, \"a balanced context requires at least one demonstartion per label\"\n",
    "        # select the same number of samples from every label\n",
    "        indices = []  # we collect all indices here\n",
    "        subset_per_label = get_balanced_subsets(dataset)\n",
    "\n",
    "        for _, samples in subset_per_label.items():\n",
    "            subset_indices = samples[\"idx\"]\n",
    "            # select num_shots // 2 samples\n",
    "            subset_indices = np.random.choice(\n",
    "                subset_indices, size=num_shots // 2, replace=False)\n",
    "            indices += list(subset_indices)\n",
    "        assert len(indices) == num_shots\n",
    "    else:\n",
    "        # just select a random subset of samples\n",
    "        indices = np.random.choice(\n",
    "            dataset['idx'], size=num_shots, replace=False)\n",
    "\n",
    "    # return _select_subset_by_ids(dataset, indices), indices\n",
    "    return _select_subset_by_idx(dataset, indices), indices\n",
    "\n",
    "\n",
    "def create_few_shot_context(\n",
    "    dataset_name,\n",
    "    dataset,\n",
    "    num_shots,\n",
    "    description=\"\",\n",
    "    remove_label=False,\n",
    "    from_indices=None,\n",
    "    balanced=False,\n",
    "    shuffle=False,\n",
    "    seed=123\n",
    "):\n",
    "    separate_description_by=\"\\n\\n\"\n",
    "    separate_shots_by=\"\\n\\n\"\n",
    "    # select samples from which the context will be constructed\n",
    "    if from_indices is not None:\n",
    "        demonstrations = _select_subset_by_ids(dataset, from_indices)\n",
    "        indices = np.array(from_indices)\n",
    "    else:\n",
    "        demonstrations, indices = _select_random_subset(\n",
    "            dataset, num_shots, balanced, seed)\n",
    "\n",
    "    if shuffle:\n",
    "        if len(demonstrations) > 0:\n",
    "            demonstrations = demonstrations.shuffle(seed)\n",
    "\n",
    "    # create context\n",
    "    context = \"\" if description == \"\" else f\"{description}{separate_description_by}\"\n",
    "    int_to_label_converter = dataset.features['label']\n",
    "\n",
    "    if task_to_keys[dataset_name][1] is not None:\n",
    "        pattern = '{prefix1}: {text1}\\n{prefix2}: {text2}'\n",
    "    else:\n",
    "        pattern = '{prefix1}: {text1}'\n",
    "    \n",
    "    for sample in demonstrations:\n",
    "        second_key_present = task_to_keys[dataset_name][1]\n",
    "        formated_sample = pattern.format(\n",
    "            prefix1=task_to_keys[dataset_name][0].capitalize(),\n",
    "            text1=sample[task_to_keys[dataset_name][0]],\n",
    "            prefix2=task_to_keys[dataset_name][1].capitalize() if second_key_present is not None else None,\n",
    "            text2=sample[task_to_keys[dataset_name][1]] if second_key_present is not None else None\n",
    "        )\n",
    "        if sample[\"label\"] == -1 or remove_label:\n",
    "            verbalized_label = \"\"\n",
    "        else:\n",
    "            verbalized_label = int_to_label_converter.int2str(sample[\"label\"])\n",
    "        context += f\"{formated_sample}\\nLabel: {verbalized_label}{separate_shots_by}\"\n",
    "\n",
    "    return context, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4c5eb7-e833-4c41-a5ee-5d77ec670bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### rte, mnli, qqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83f3e44-6dff-41b1-a9ea-5b686f121d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: The Collection and Analysis of Qualitative Data in Evaluation Research.\n",
      "Hypothesis: Only quantitative data can be used in evaluation research.\n",
      "Label: contradiction\n",
      "\n",
      "Premise: The total producer costs estimated by EPA including the costs of certification, addization of the detergents, recordkeeping and enforcement through the year 2000 is almost $704 million.\n",
      "Hypothesis: The costs of certification are not included in EPA's total producer costs estimates.\n",
      "Label: contradiction\n",
      "\n",
      "Premise: If you watch the action closely, you can learn a lot about Indian people by what makes them cheer, laugh, or weep.\n",
      "Hypothesis: You can learn a lot about Indian people by watching their actions.\n",
      "Label: entailment\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set_used='mnli'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['train'],\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb9d961-222a-4a1b-acf5-9111c83c2ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: A 1997 Henry J. Kaiser Family Foundation survey found that Americans in managed care plans are basically content with their own care.\n",
      "Hypothesis: the Henry Kaiser foundation shows that people like their healthcare\n",
      "Label: entailment\n",
      "\n",
      "Premise: In DOD's current acquisition environment, the customer is willing to trade time and money for the highest performing weapon system possible.\n",
      "Hypothesis: Having the highest performing weapon system is of paramount importance being prioritized above time and money.\n",
      "Label: entailment\n",
      "\n",
      "Premise: Eh! Monsieur Lawrence, called Poirot. \n",
      "Hypothesis: Poirot requested the attention of Monsieur Lawrence.\n",
      "Label: entailment\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set_used='mnli'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['validation_matched'],\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eac89f93-2011-44fb-9e78-f36191718ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence1: Britain agreed to lift by March 31 a 150-mile military protection zone enforced around the islands since Argentina invaded them in 1982.\n",
      "Sentence2: The military protection zone around Falklands was lifted.\n",
      "Label: entailment\n",
      "\n",
      "Sentence1: Clonaid, which claims to have produced 13 cloned babies worldwide, told the Streats daily newspaper two Singaporean couples had signed deals agreeing to pay $200,000 to conceive children through cloning.\n",
      "Sentence2: Clonaid has cloned 13 babies.\n",
      "Label: entailment\n",
      "\n",
      "Sentence1: In 1927 Harnold Lamb wrote a biography of Genghis Khan, and following on its success turned more and more to the writing of non-fiction, penning numerous biographies and history books until his death in 1962.\n",
      "Sentence2: Harnold Lamb authored many biographies.\n",
      "Label: entailment\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set_used='rte'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['train'],\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ce2f27-5d3f-4786-96ba-a4a8c9816334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence1: Italian film-maker, Fellini was awarded an honorary Oscar for lifetime achievement. He died on October 31, 1993.\n",
      "Sentence2: An Italian director is awarded an honorary Oscar.\n",
      "Label: entailment\n",
      "\n",
      "Sentence1: The Daily Telegraph, most prized asset in Lord Conrad Black's crumbling media empire, has been sold to Britain's Barclay twins.\n",
      "Sentence2: Daily telegraph is sold.\n",
      "Label: entailment\n",
      "\n",
      "Sentence1: Monica Meadows, a 22-year-old model from Atlanta, was shot in the shoulder on a subway car in New York City.\n",
      "Sentence2: Monica Meadows, 23, was shot in shoulder while riding a subway car in New York City\n",
      "Label: not_entailment\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set_used='rte'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['validation'],\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a533cfd5-e38e-4a82-ab97-4cf35add9dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: How soon one can learn guitar?\n",
      "Question2: What is the easiest way to learn guitar?\n",
      "Label: not_duplicate\n",
      "\n",
      "Question1: Does global warming exist?\n",
      "Question2: Is Global warming real or a hoax?\n",
      "Label: duplicate\n",
      "\n",
      "Question1: Which laptop configuration is better? I3-5th gen with 8gb ram or i5-6th gen with 4gb ram.?\n",
      "Question2: Which laptop configuration is better? I3-5th gen with 8gb ram or i5-6th gen with 4gb ram.\n",
      "Label: duplicate\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set_used='qqp'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['train'],\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f9f0ee-aef0-44f6-b1f4-7ea90a18ce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: Where can I find a date picker similar to the one in Google Analytics? Not Good\n",
      "Question2: Is it a good idea to block Google Analytics?\n",
      "Label: not_duplicate\n",
      "\n",
      "Question1: What is Fiscal deficite?\n",
      "Question2: What is Fiscal Deficit?\n",
      "Label: duplicate\n",
      "\n",
      "Question1: Why do noses never stop growing?\n",
      "Question2: Is it true your nose never stops growing?\n",
      "Label: duplicate\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set_used='qqp'\n",
    "datasets, labels, num_labels = load_glue_datasets(data_set_used)\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets['validation'],\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a948aa2-1943-468d-a13a-d42a6aedccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: The senators admired the lawyers .\n",
      "Hypothesis: The lawyers admired the senators .\n",
      "Label: non-entailment\n",
      "\n",
      "Premise: The doctors advised the artists who the presidents contacted .\n",
      "Hypothesis: The presidents advised the doctors .\n",
      "Label: non-entailment\n",
      "\n",
      "Premise: The athlete was thanked by the banker .\n",
      "Hypothesis: The banker thanked the athlete .\n",
      "Label: entailment\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set_used='hans'\n",
    "datasets, subset = load_hans_dataset(heuristic='lexical_overlap')\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    datasets,\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "181b6e7a-4496-46ac-b000-fc69b6d39811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence1: Is LinkedIn a good acquisition for Microsoft ? Does it make strategic sense ?\n",
      "Sentence2: Is LinkedIn a strategic acquisition for Microsoft ? Does it make good sense ?\n",
      "Label: non_duplicate\n",
      "\n",
      "Sentence1: What are some of the good so-called Indian `Art-films ' ?\n",
      "Sentence2: What are some of the Indian so-called good `Art-films ' ?\n",
      "Label: non_duplicate\n",
      "\n",
      "Sentence1: I 'm 16 years old girl . I am 5 ' 3 '' tall and weigh 80 kg . How do I lose weight ?\n",
      "Sentence2: I am 16 years old girl . I 'm 5 3 `` tall and weigh 80 kg . How do I lose weight ?\n",
      "Label: duplicate\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set_used='paws-qqp'\n",
    "data_path = os.path.join(os.getcwd(),'data')\n",
    "dataset, dataset_name = load_paws_qqp_dataset(path=os.path.join(data_path,'paws_qqp','dev_and_test.tsv'))\n",
    "context, indices = create_few_shot_context(\n",
    "    data_set_used,\n",
    "    dataset,\n",
    "    3\n",
    ")\n",
    "print(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
